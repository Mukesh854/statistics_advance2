{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15de3975-3b56-4de2-b35e-ec1c11ad61d2",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef17a45-f00d-452a-adb2-936fdc72be91",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical concepts used in probability theory and statistics to describe the distribution of probability for random variables.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The PMF is used for discrete random variables, which are variables that can take on a countable set of distinct values. The PMF gives the probability of a random variable taking on a specific value.\n",
    "Example:\n",
    "Consider rolling a fair six-sided die. The random variable X represents the outcome of the roll. The possible outcomes are 1, 2, 3, 4, 5, and 6. The PMF for this scenario would give the probability of each of these outcomes:\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "\n",
    "The PDF is used for continuous random variables, which can take on any value within a certain range. The PDF gives the relative likelihood of the random variable falling within a specific interval.\n",
    "Example:\n",
    "Consider the height of adult individuals. The random variable Y represents the height. Heights can be any real number within a certain range (e.g., from 4 feet to 7 feet). The PDF for this scenario would give the probability density at different height values, but the actual probability of having a specific height is zero due to the continuous nature of the variable. Instead, the area under the PDF curve within a certain interval represents the probability of the variable falling within that interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96949ee-4fff-4bbe-96f7-a3326fd329df",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596993b-2c8b-4959-a23c-d0171e6de9f9",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a concept in probability theory and statistics that provides information about the probability that a random variable takes on a value less than or equal to a given value. It gives the cumulative probability distribution of the random variable.\n",
    "\n",
    "Mathematically, for a random variable X, the CDF is denoted as F(x) and is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "In words, the CDF at a particular value x gives the probability that the random variable X is less than or equal to x.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's consider the rolling of a fair six-sided die again. The random variable X represents the outcome of the roll. The CDF for this scenario would be:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "For each possible value of x (1, 2, 3, 4, 5, 6), the CDF would be the cumulative probability of getting a value less than or equal to x:\n",
    "\n",
    "F(1) = P(X ≤ 1) = 1/6\n",
    "\n",
    "F(2) = P(X ≤ 2) = 2/6 = 1/3\n",
    "\n",
    "F(3) = P(X ≤ 3) = 3/6 = 1/2\n",
    "\n",
    "F(4) = P(X ≤ 4) = 4/6 = 2/3\n",
    "\n",
    "F(5) = P(X ≤ 5) = 5/6\n",
    "\n",
    "F(6) = P(X ≤ 6) = 6/6 = 1\n",
    "\n",
    "The CDF gives you the cumulative probability of getting a value less than or equal to each possible outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b5eb5-2301-4465-8806-d6882bce670f",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56353e8a-1c06-486e-9e91-c0a4554c71dd",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is a widely used probability distribution in statistics. It's often used to model real-world phenomena due to its versatile and ubiquitous nature. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1) Height of individuals\n",
    "\n",
    "2) IQ scores\n",
    "\n",
    "3) Measurement errors.\n",
    "\n",
    "4) Random variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb5bd2-9c9d-4320-81e4-cd66e62d17c4",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f3f09-7e06-4bc4-b77c-dda07a7a5d1e",
   "metadata": {},
   "source": [
    "Normal distribution also known as gaussian distribution, holds significant importance in various fields due to it's mathematical properties and prevalence in real world phenomena.\n",
    "\n",
    "Some key reasons for the importance of the normal distribution are:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is central to the Central Limit Theorem, which states that the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution. This property makes the normal distribution a fundamental concept for statistical inference.\n",
    "\n",
    "Statistical Analysis: Many statistical methods and hypothesis tests assume normality in the data. This assumption simplifies calculations and allows for the use of powerful parametric tests.\n",
    "\n",
    "Predictive Modeling: Many machine learning algorithms and predictive models assume that the residuals (errors) of the model are normally distributed. This assumption is crucial for making reliable predictions.\n",
    "\n",
    "Risk Management: In finance and risk management, the normal distribution is often used to model market returns and estimate risks associated with financial assets.\n",
    "\n",
    "Quality Control: In manufacturing and quality control processes, the normal distribution is used to analyze process variations and set tolerance limits.\n",
    "\n",
    "Real-life examples of situations where the normal distribution is observed include:\n",
    "\n",
    "1) Height of individuals.\n",
    "\n",
    "2) Exam scores.\n",
    "\n",
    "3) Errors in measurement.\n",
    "\n",
    "4) Blood pressure.\n",
    "\n",
    "5) IQ score.\n",
    "\n",
    "6) Body mass index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afcd8a0-3d06-4d56-8792-be36198de431",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608cef50-439e-4085-b70c-3c5fe47e2362",
   "metadata": {},
   "source": [
    "The Bernoulli Distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success and failure. It's named after Jacob Bernoulli, a Swiss mathematician. The distribution is characterized by a single parameter, often denoted as \"p,\" which represents the probability of success in a single trial.\n",
    "\n",
    "Mathematically, the probability mass function (PMF) of the Bernoulli Distribution is as follows:\n",
    "\n",
    "P(X = 1) = p (probability of success)\n",
    "P(X = 0) = 1 - p (probability of failure)\n",
    "\n",
    "Here, X is a random variable representing the outcome of the experiment, where 1 might represent success and 0 represents failure.\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "Tossing a fair coin can be modeled using a Bernoulli Distribution. Let's say we define \"Heads\" as a success and \"Tails\" as a failure. If the coin is fair, then the probability of getting Heads (success) is 0.5 (p = 0.5), and the probability of getting Tails (failure) is also 0.5. This can be represented using the Bernoulli Distribution.\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Represents a single trial or experiment with two possible outcomes.\n",
    "Binomial Distribution: Represents the number of successes in a fixed number of independent Bernoulli trials (experiments).\n",
    "Parameters:\n",
    "\n",
    "Bernoulli Distribution: Has a single parameter, p, representing the probability of success in a single trial.\n",
    "Binomial Distribution: Has two parameters, n (number of trials) and p (probability of success in each trial).\n",
    "Number of Outcomes:\n",
    "\n",
    "Bernoulli Distribution: Only two possible outcomes: success (1) or failure (0).\n",
    "Binomial Distribution: Represents the number of successes (k) out of n trials, where k can take values from 0 to n.\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "Bernoulli Distribution: The PMF gives the probabilities of success (p) and failure (1 - p).\n",
    "Binomial Distribution: The PMF gives the probability of getting exactly k successes out of n trials, given by the binomial coefficient and the probabilities of success and failure.\n",
    "Use Cases:\n",
    "\n",
    "Bernoulli Distribution: Used for modeling a single binary experiment, like a coin toss or a single event with two possible outcomes.\n",
    "Binomial Distribution: Used for counting the number of successes in a fixed number of independent trials, such as the number of heads in multiple coin tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f0fc4-4e3a-46e2-8261-8ec15d18cfa2",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df13cd-a6f1-4fea-ab82-8d0504d01334",
   "metadata": {},
   "source": [
    "The Z-score is calculated as:\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "X is the value we want to find the probability for (in this case, 60),\n",
    "μ is the mean of the dataset (50), and\n",
    "σ is the standard deviation of the dataset (10).\n",
    "Substitute the values:\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "From the z-score table the fraction of data within the observation greater than 60 is .8413\n",
    "\n",
    "Therefore:\n",
    "\n",
    "P(Z > 1) = 1 - 0.8413 = 0.1587\n",
    "\n",
    "So, the probability that a randomly selected observation from the given normally distributed dataset will be greater than 60 is approximately 0.1587, or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1c71-8bb3-41e5-bec5-fdc30841fcb9",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f06467-a7a3-48e6-aaf3-a4d4dbf10464",
   "metadata": {},
   "source": [
    "The Uniform Distribution is a probability distribution that describes a situation where all possible outcomes within a certain range are equally likely. In other words, every value within the specified interval has the same probability of occurring. \n",
    "\n",
    "Mathematically, the probability density function (PDF) of a continuous uniform distribution is given by:\n",
    "\n",
    "f(x) = 1 / (b - a), if a ≤ x ≤ b\n",
    "\n",
    "Where:\n",
    "\n",
    "a is the lower bound of the distribution\n",
    "\n",
    "b is the upper bound of the distribution\n",
    "\n",
    "x is a value within the range [a, b]\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "\n",
    "Consider rolling a fair six-sided die. The random variable X represents the outcome of the roll. Since each face of the die is equally likely to appear, the distribution of X follows a discrete uniform distribution.\n",
    "\n",
    "In this case, a = 1 (lowest possible outcome) and b = 6 (highest possible outcome). The probability of getting any specific outcome is:\n",
    "\n",
    "P(X = 1) = 1 / 6\n",
    "\n",
    "P(X = 2) = 1 / 6\n",
    "\n",
    "P(X = 3) = 1 / 6\n",
    "\n",
    "P(X = 4) = 1 / 6\n",
    "\n",
    "P(X = 5) = 1 / 6\n",
    "\n",
    "P(X = 6) = 1 / 6\n",
    "\n",
    "Each outcome has an equal probability of 1/6, making this a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262583d3-beec-42eb-9325-acb17f8bb74a",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1207a-8e09-4634-bf01-399ed6bced2d",
   "metadata": {},
   "source": [
    "The Z-score, also known as the standard score or standardized value, is a statistical measure that quantifies the number of standard deviations a data point is away from the mean of a distribution. It is used to compare and standardize values across different distributions, allowing for meaningful comparisons and assessments of relative positions.\n",
    "\n",
    "Mathematically, the Z-score for a data point x in a distribution with mean μ and standard deviation σ is calculated as:\n",
    "\n",
    "Z = (x - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "x is the individual data point\n",
    "\n",
    "μ is the mean of the distribution\n",
    "\n",
    "σ is the standard deviation of the distribution\n",
    "\n",
    "The Z-score indicates how many standard deviations a data point is above or below the mean. Positive Z-scores mean the data point is above the mean, while negative Z-scores mean the data point is below the mean.\n",
    "\n",
    "Importance of Z-scores:\n",
    "\n",
    "Standardization: Z-scores standardize data across different distributions, allowing for meaningful comparisons between data points from different contexts. This makes it easier to identify outliers and extreme values.\n",
    "\n",
    "Normalization: Z-scores transform data into a common scale with a mean of 0 and a standard deviation of 1. This is useful when working with algorithms or models that assume normally distributed data.\n",
    "\n",
    "Identifying Outliers: Z-scores help identify outliers, which are data points that significantly deviate from the mean. Outliers often have Z-scores that are far from the mean.\n",
    "\n",
    "Data Interpretation: Z-scores provide context for individual data points by indicating how typical or atypical they are within a distribution.\n",
    "\n",
    "Probability and Percentiles: Z-scores can be used to calculate the probability of a data point occurring in a normal distribution and to determine percentiles.\n",
    "\n",
    "Data Transformation: Z-scores are used in data transformation processes to make data conform to certain assumptions, such as normality, in statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539f64f-b5e2-4529-bb6f-8afb390f3589",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea2b6b-3534-4ec9-8be0-7239998af555",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the distribution of the sample means (or sums) of a large enough number of independent, identically distributed random variables will approximate a normal distribution, regardless of the original distribution of the variables themselves. In simpler terms, even if the individual data points are not normally distributed, the distribution of their means tends to become normal as the sample size increases.\n",
    "\n",
    "The Central Limit Theorem is particularly powerful because it enables us to make probabilistic inferences about sample means even when we don't know the underlying distribution of the population. It forms the basis for many statistical techniques and hypothesis tests.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Foundation for Inferential Statistics: The Central Limit Theorem is the foundation for many inferential statistical methods. It allows us to use normal distribution properties to make inferences about population parameters based on sample data.\n",
    "\n",
    "Large Sample Sizes: The CLT suggests that with a sufficiently large sample size, the distribution of sample means becomes approximately normal, regardless of the original distribution. This is why normality assumptions are often made in statistical analyses.\n",
    "\n",
    "Accuracy of Estimation: The CLT allows us to estimate population parameters (like the population mean) with greater accuracy using the sample mean. This is crucial for making accurate predictions and decisions.\n",
    "\n",
    "Hypothesis Testing: Many hypothesis tests, such as t-tests and z-tests, rely on the assumptions of normality. The CLT justifies these tests when applied to large samples, even if the original population distribution is not normal.\n",
    "\n",
    "Real-World Applications: In real-world scenarios, we often deal with large samples or populations. The Central Limit Theorem helps us apply statistical methods more broadly, as long as we have sufficiently large sample sizes.\n",
    "\n",
    "Modeling Complex Phenomena: The CLT allows us to simplify complex distributions and phenomena into more manageable and predictable normal distributions for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16438da2-40f8-4361-aecb-2b757249e82d",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18be1f8-f4b5-4066-8a3a-f58473317916",
   "metadata": {},
   "source": [
    "Certain assumptions must be met:\n",
    "    \n",
    "Independence: The observations in the sample must be independent of each other. This means that the value of one observation should not influence or be influenced by the value of another observation.\n",
    "\n",
    "Identically Distributed: The observations must be drawn from the same population and have the same underlying distribution. This assumption ensures consistency across the sample.\n",
    "\n",
    "Random Sampling: The observations should be randomly selected from the population. This helps to ensure that the sample is representative of the population.\n",
    "\n",
    "Sample Size: The sample size should be sufficiently large. While there is no fixed rule for what constitutes a \"large\" sample size, as a rule of thumb, a sample size of 30 or greater is often considered adequate for the CLT to work reasonably well.\n",
    "\n",
    "Finite Variance: The population from which the samples are drawn should have a finite variance (i.e., the spread of the data points is not infinite).\n",
    "\n",
    "No Extreme Outliers: The presence of extreme outliers in the sample can affect the validity of the CLT, especially if they significantly impact the sample mean.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c64e98-0b70-4460-917b-d747297fed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e912a-4b01-4f1d-be63-d1dc19cf217a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
